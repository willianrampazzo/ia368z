{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimativa preços de venda do dataset Boston_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos problemas clássicos de machine learning é a previsão dos preços das casas de Boston apresentado no final da década de 1970.\n",
    "\n",
    "Existe uma competição no Kaggle que utiliza este dataset:\n",
    "https://www.kaggle.com/c/boston-housing\n",
    "\n",
    "O objetivo desse notebook é fazer a previsão dos preços das casas utilizando uma rede neural com uma camada escondida de 40 neurônios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:25:26.711160Z",
     "start_time": "2017-10-22T22:25:25.577299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from torch.optim.lr_scheduler import MultiStepLR, StepLR\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import lib.pytorch_trainer as ptt\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura do Dataset já normalizado: [boston_housing.ipynb](boston_housing.ipynb)\n",
    "- **Atenção**: se houver erro em não achar o arquivo, executar o notebook boston_housing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:25:26.720559Z",
     "start_time": "2017-10-22T22:25:26.713736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datain = np.load('../data/boston_housing_normalize.npz')\n",
    "\n",
    "x, y = datain['Xtra'], datain['ytra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:25:26.728514Z",
     "start_time": "2017-10-22T22:25:26.722746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 506\n",
      "n_attributes: 13\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_attributes = x.shape\n",
    "print('n_samples:', n_samples)\n",
    "print('n_attributes:', n_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão para Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:25:26.737303Z",
     "start_time": "2017-10-22T22:25:26.730608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x)\n",
    "y_train = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede, uma camada escondida de 40 neurônios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:28.533326Z",
     "start_time": "2017-10-22T22:35:28.515061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model (\n",
       "  (layer1): Linear (13 -> 40)\n",
       "  (ativ1): ReLU ()\n",
       "  (layer2): Linear (40 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_attributes, 40)\n",
    "        self.ativ1  = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(40, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.ativ1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCallback(ptt.DeepNetTrainer):\n",
    "    def __init__(self):\n",
    "        self.metrics = {'mean':list([]), 'var':list([])}\n",
    "\n",
    "    def on_train_begin(self, n_epochs, metrics):\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, n_epochs, metrics):\n",
    "        plt.plot(np.arange(len(self.metrics['mean'])), self.metrics['mean'],\n",
    "                 np.arange(len(self.metrics['var'])), self.metrics['var'])\n",
    "\n",
    "    def on_epoch_begin(self, epoch, metrics):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, metrics):\n",
    "        self.metrics['mean'].append(self.trainer.model.state_dict()['layer1.weight'].mean())\n",
    "        self.metrics['var'].append(self.trainer.model.state_dict()['layer1.weight'].var())\n",
    "\n",
    "    def on_batch_begin(self, epoch, batch, mb_size):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, epoch, batch, y_pred, y_true, loss):\n",
    "        pass\n",
    "\n",
    "    def on_vbatch_begin(self, epoch, batch, mb_size):\n",
    "        pass\n",
    "\n",
    "    def on_vbatch_end(self, epoch, batch, y_pred, y_true, loss):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop(ptt.DeepNetTrainer):\n",
    "    def __init__(self, patience):\n",
    "        self.patience = patience\n",
    "        self.patience_count = 0\n",
    "        self.best_loss = 1e10\n",
    "\n",
    "    def on_train_begin(self, n_epochs, metrics):\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, n_epochs, metrics):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, metrics):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, metrics):\n",
    "        if (metrics['valid']['losses'][-1] < self.best_loss):\n",
    "            self.best_loss = metrics['valid']['losses'][-1]\n",
    "            self.patience_count = 0\n",
    "            print('Loss improved on validation!')\n",
    "        else:\n",
    "            self.patience_count += 1\n",
    "            \n",
    "        if (self.patience_count > self.patience):\n",
    "            print('Early stopping!')\n",
    "            raise KeyboardInterrupt\n",
    "    \n",
    "    def on_batch_begin(self, epoch, batch, mb_size):\n",
    "        pass\n",
    "\n",
    "    def on_batch_end(self, epoch, batch, y_pred, y_true, loss):\n",
    "        pass\n",
    "\n",
    "    def on_vbatch_begin(self, epoch, batch, mb_size):\n",
    "        pass\n",
    "\n",
    "    def on_vbatch_end(self, epoch, batch, y_pred, y_true, loss):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros do otimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A escolha dos parâmetros para o treinamento é crítica. A escolha do learning rate,\n",
    "do método de ótimização, do tamanho do mini-batch, do número de camadas, do número de neurônios em\n",
    "cada camada, são todas críticas para o sucesso do estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:29.372547Z",
     "start_time": "2017-10-22T22:35:29.366026Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.00001, momentum=0.9, nesterov=True)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0005, alpha=0.7)\n",
    "savebest = ptt.ModelCheckpoint('../../models/bostonhousing',reset=True, verbose=1)\n",
    "\n",
    "callback = MyCallback()\n",
    "\n",
    "earlystop = EarlyStop(2)\n",
    "\n",
    "trainer = ptt.DeepNetTrainer(\n",
    "        model =         model,\n",
    "        criterion =     criterion,\n",
    "        optimizer =     optimizer,\n",
    "        #callbacks =     [savebest,ptt.PrintCallback()]\n",
    "        callbacks =     [ptt.PrintCallback(), earlystop]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:46.735289Z",
     "start_time": "2017-10-22T22:35:30.412133Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 50 epochs\n",
      "  1:   0.0s   T: 12.11414   V: 10.00125 best\n",
      "Loss improved on validation!\n",
      "  2:   0.0s   T: 12.07716   V: 9.80774 best\n",
      "Loss improved on validation!\n",
      "  3:   0.0s   T: 12.01750   V: 9.83229 \n",
      "  4:   0.0s   T: 12.01036   V: 9.75776 best\n",
      "Loss improved on validation!\n",
      "  5:   0.0s   T: 11.94754   V: 9.85425 \n",
      "  6:   0.0s   T: 11.95420   V: 9.79718 \n",
      "  7:   0.0s   T: 11.91512   V: 9.73473 best\n",
      "Loss improved on validation!\n",
      "  8:   0.0s   T: 11.85589   V: 9.58090 best\n",
      "Loss improved on validation!\n",
      "  9:   0.0s   T: 11.84674   V: 9.65348 \n",
      " 10:   0.0s   T: 11.81360   V: 9.86591 \n",
      " 11:   0.0s   T: 11.78405   V: 9.69286 \n",
      "Early stopping!\n",
      "Stop training at epoch: 11/50\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(50, x_train, y_train, valid_split=0.2, shuffle=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:46.942112Z",
     "start_time": "2017-10-22T22:35:46.737352Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = trainer.metrics['train']['losses']\n",
    "valid_loss = trainer.metrics['valid']['losses']\n",
    "epochs = np.arange(len(train_loss))\n",
    "plt.plot(epochs, train_loss,\n",
    "         epochs, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:46.948744Z",
     "start_time": "2017-10-22T22:35:46.944106Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.load_state('../../models/bostonhousing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:47.878730Z",
     "start_time": "2017-10-22T22:35:47.830676Z"
    }
   },
   "outputs": [],
   "source": [
    "eval = trainer.evaluate(x_train,y_train)\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:48.937652Z",
     "start_time": "2017-10-22T22:35:48.717677Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = trainer.metrics['train']['losses']\n",
    "valid_loss = trainer.metrics['valid']['losses']\n",
    "epochs = np.arange(len(train_loss))\n",
    "plt.plot(epochs, train_loss,\n",
    "         epochs, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-22T22:35:52.193413Z",
     "start_time": "2017-10-22T22:35:52.185568Z"
    }
   },
   "outputs": [],
   "source": [
    "print('MSE:',valid_loss[-1])\n",
    "print('RMSE:', np.sqrt(valid_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-19T11:45:27.400682",
     "start_time": "2017-10-19T11:45:27.395525"
    }
   },
   "source": [
    "- Troque os hyperparâmetros para verificar se você consegue obter valores melhores. A forma de\n",
    "  escolha e alteração de parâmetros é algo que se aprende com a experiência. Procure fazer\n",
    "  sintonias finas, variando apenas um ou poucos parâmetros de cada vez.\n",
    "  \n",
    "  Parâmetros que podem ser trocados:\n",
    "  - learning rate\n",
    "  - n. de camadas\n",
    "  - n. de neurônios\n",
    "  - troca de função de ativação\n",
    "  - método de otimizador do gradiente descendente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
