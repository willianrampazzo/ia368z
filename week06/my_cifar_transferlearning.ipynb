{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10 - exercicio de classificar 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer classificação de 3 classes usando rede neural convolucional.\n",
    "Não utilizar o pacote sklearn. Apenas o Keras e o NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não utilizar a função de acompanhamento de gráficos durante o treinamento.\n",
    "\n",
    "Gerar uma figura mosaic que contenha as 5 imagens de classificação correta de menor probabilidade de predição.\n",
    "\n",
    "Gerar esta figura com o nome: cifar_fig.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential, load_model, Model, Input\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.regularizers as reg\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/etc/jupyterhub/ia368z_2s2017/datasets/cifar10-redux.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X_train']\n",
    "y = data['y_train']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "X = np.swapaxes(X, 2, 3)\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "X_test = np.swapaxes(X_test, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 32, 32, 3), (2000,), (500, 32, 32, 3), (500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('uint8'), dtype('uint8'), dtype('int64'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype, y.dtype, X_test.dtype, y_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "X /= 255.\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255.\n",
    "\n",
    "# transforma labels em 0, 1 e 2, ao invés de 3, 4 e 5\n",
    "y = y - 3\n",
    "y_test = y_test - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados de treinamento em treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605\n",
      "395\n",
      "(1605, 32, 32, 3)\n",
      "(395, 32, 32, 3)\n",
      "(1605,)\n",
      "(395,)\n"
     ]
    }
   ],
   "source": [
    "# numero de amostras\n",
    "nb_data = X.shape[0]\n",
    "\n",
    "# semente fixa para dar reproducibilidade\n",
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "\n",
    "msk = np.random.rand(nb_data) < 0.80\n",
    "X_train = X[msk]\n",
    "X_validate = X[~msk]\n",
    "y_train = y[msk]\n",
    "y_validate = y[~msk]\n",
    "\n",
    "nb_train = X_train.shape[0]\n",
    "nb_validate = X_validate.shape[0]\n",
    "\n",
    "print(nb_train)\n",
    "print(nb_validate)\n",
    "print(X_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma o vetor de labels para o formato de one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 3\n",
    "\n",
    "y_oh = np_utils.to_categorical(y, nb_classes)\n",
    "y_train_oh = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_validate_oh = np_utils.to_categorical(y_validate, nb_classes)\n",
    "y_test_oh = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a rede VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = Input(shape=(32,32, 3))\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_tensor=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustando a rede para os dados do CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# com a rede completa: #41%\n",
    "#vgg.layers.pop() # 48.80%\n",
    "#vgg.layers.pop() # 45.00%\n",
    "#vgg.layers.pop() # 44.80%\n",
    "#vgg.layers.pop() # 46.80%\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo as features com a VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 512)\n",
      "(395, 1, 1, 512)\n",
      "(500, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "train_features = vgg.predict(X_train)\n",
    "valid_features = vgg.predict(X_validate)\n",
    "test_features = vgg.predict(X_test)\n",
    "\n",
    "print(train_features.shape[1:])\n",
    "print(valid_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construíndo a CNN com o Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 66,051\n",
      "Trainable params: 66,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Definindo a rede\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(nb_classes, kernel_regularizer=reg.l2(0.025)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'\n",
    "#opt = RMSprop()\n",
    "opt = Adam()\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='cifar10.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "lrreduction = ReduceLROnPlateau(monitor='val_acc', patience=7, verbose=1, factor=0.8, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1605 samples, validate on 395 samples\n",
      "Epoch 1/100\n",
      "1440/1605 [=========================>....] - ETA: 0s - loss: 1.3012 - acc: 0.4389Epoch 00000: val_acc improved from -inf to 0.61772, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 1.2851 - acc: 0.4436 - val_loss: 1.0115 - val_acc: 0.6177\n",
      "Epoch 2/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 1.0318 - acc: 0.5466Epoch 00001: val_acc improved from 0.61772 to 0.61772, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 1.0341 - acc: 0.5483 - val_loss: 0.9415 - val_acc: 0.6177\n",
      "Epoch 3/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.9650 - acc: 0.5858Epoch 00002: val_acc improved from 0.61772 to 0.62785, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.9606 - acc: 0.5894 - val_loss: 0.8920 - val_acc: 0.6278\n",
      "Epoch 4/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.9080 - acc: 0.6189Epoch 00003: val_acc improved from 0.62785 to 0.63544, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.9051 - acc: 0.6187 - val_loss: 0.8667 - val_acc: 0.6354\n",
      "Epoch 5/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.8846 - acc: 0.6318Epoch 00004: val_acc improved from 0.63544 to 0.64557, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.8850 - acc: 0.6343 - val_loss: 0.8480 - val_acc: 0.6456\n",
      "Epoch 6/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.8467 - acc: 0.6682Epoch 00005: val_acc improved from 0.64557 to 0.65063, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.8509 - acc: 0.6617 - val_loss: 0.8258 - val_acc: 0.6506\n",
      "Epoch 7/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.8421 - acc: 0.6453Epoch 00006: val_acc improved from 0.65063 to 0.65316, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.8365 - acc: 0.6517 - val_loss: 0.8262 - val_acc: 0.6532\n",
      "Epoch 8/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.8429 - acc: 0.6392Epoch 00007: val_acc improved from 0.65316 to 0.66835, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.8411 - acc: 0.6449 - val_loss: 0.8142 - val_acc: 0.6684\n",
      "Epoch 9/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7942 - acc: 0.6615Epoch 00008: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7874 - acc: 0.6667 - val_loss: 0.8019 - val_acc: 0.6557\n",
      "Epoch 10/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7971 - acc: 0.6669Epoch 00009: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7944 - acc: 0.6692 - val_loss: 0.8065 - val_acc: 0.6608\n",
      "Epoch 11/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7995 - acc: 0.6662Epoch 00010: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7960 - acc: 0.6685 - val_loss: 0.7973 - val_acc: 0.6608\n",
      "Epoch 12/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7686 - acc: 0.6932Epoch 00011: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7706 - acc: 0.6897 - val_loss: 0.8127 - val_acc: 0.6532\n",
      "Epoch 13/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7762 - acc: 0.6730Epoch 00012: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7783 - acc: 0.6729 - val_loss: 0.7894 - val_acc: 0.6532\n",
      "Epoch 14/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7580 - acc: 0.6986Epoch 00013: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7573 - acc: 0.6947 - val_loss: 0.7893 - val_acc: 0.6582\n",
      "Epoch 15/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7643 - acc: 0.6905Epoch 00014: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7694 - acc: 0.6866 - val_loss: 0.7843 - val_acc: 0.6557\n",
      "Epoch 16/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7575 - acc: 0.6838Epoch 00015: val_acc improved from 0.66835 to 0.67089, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.7556 - acc: 0.6835 - val_loss: 0.7792 - val_acc: 0.6709\n",
      "Epoch 17/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7450 - acc: 0.6946Epoch 00016: val_acc improved from 0.67089 to 0.67342, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.7378 - acc: 0.6984 - val_loss: 0.7767 - val_acc: 0.6734\n",
      "Epoch 18/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7233 - acc: 0.7068Epoch 00017: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7292 - acc: 0.7016 - val_loss: 0.7787 - val_acc: 0.6557\n",
      "Epoch 19/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7300 - acc: 0.6905Epoch 00018: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7269 - acc: 0.6928 - val_loss: 0.7731 - val_acc: 0.6633\n",
      "Epoch 20/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7138 - acc: 0.7169Epoch 00019: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7174 - acc: 0.7146 - val_loss: 0.7738 - val_acc: 0.6684\n",
      "Epoch 21/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7135 - acc: 0.7088Epoch 00020: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7124 - acc: 0.7078 - val_loss: 0.7724 - val_acc: 0.6658\n",
      "Epoch 22/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7161 - acc: 0.7000Epoch 00021: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7099 - acc: 0.7034 - val_loss: 0.7699 - val_acc: 0.6633\n",
      "Epoch 23/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7123 - acc: 0.7108Epoch 00022: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.7077 - acc: 0.7134 - val_loss: 0.7686 - val_acc: 0.6684\n",
      "Epoch 24/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6964 - acc: 0.7209Epoch 00023: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6982 - acc: 0.7196 - val_loss: 0.7699 - val_acc: 0.6633\n",
      "Epoch 25/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.7113 - acc: 0.7081Epoch 00024: val_acc did not improve\n",
      "\n",
      "Epoch 00024: reducing learning rate to 0.000800000037997961.\n",
      "1605/1605 [==============================] - 0s - loss: 0.7118 - acc: 0.7128 - val_loss: 0.7721 - val_acc: 0.6608\n",
      "Epoch 26/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6913 - acc: 0.7196Epoch 00025: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6888 - acc: 0.7184 - val_loss: 0.7719 - val_acc: 0.6658\n",
      "Epoch 27/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6870 - acc: 0.7365Epoch 00026: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6868 - acc: 0.7340 - val_loss: 0.7721 - val_acc: 0.6582\n",
      "Epoch 28/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6770 - acc: 0.7311Epoch 00027: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6779 - acc: 0.7327 - val_loss: 0.7657 - val_acc: 0.6633\n",
      "Epoch 29/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6721 - acc: 0.7318Epoch 00028: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6686 - acc: 0.7340 - val_loss: 0.7662 - val_acc: 0.6709\n",
      "Epoch 30/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6868 - acc: 0.7291Epoch 00029: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6870 - acc: 0.7302 - val_loss: 0.7669 - val_acc: 0.6582\n",
      "Epoch 31/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6677 - acc: 0.7311Epoch 00030: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6673 - acc: 0.7296 - val_loss: 0.7665 - val_acc: 0.6633\n",
      "Epoch 32/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6791 - acc: 0.7338Epoch 00031: val_acc improved from 0.67342 to 0.67848, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 0s - loss: 0.6756 - acc: 0.7321 - val_loss: 0.7738 - val_acc: 0.6785\n",
      "Epoch 33/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6521 - acc: 0.7365Epoch 00032: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6518 - acc: 0.7377 - val_loss: 0.7681 - val_acc: 0.6734\n",
      "Epoch 34/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6572 - acc: 0.7405Epoch 00033: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6637 - acc: 0.7383 - val_loss: 0.7618 - val_acc: 0.6633\n",
      "Epoch 35/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6621 - acc: 0.7331Epoch 00034: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6620 - acc: 0.7321 - val_loss: 0.7680 - val_acc: 0.6532\n",
      "Epoch 36/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6342 - acc: 0.7493Epoch 00035: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6415 - acc: 0.7483 - val_loss: 0.7619 - val_acc: 0.6684\n",
      "Epoch 37/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6548 - acc: 0.7426Epoch 00036: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6565 - acc: 0.7421 - val_loss: 0.7616 - val_acc: 0.6608\n",
      "Epoch 38/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6488 - acc: 0.7426Epoch 00037: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6520 - acc: 0.7396 - val_loss: 0.7618 - val_acc: 0.6582\n",
      "Epoch 39/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6339 - acc: 0.7405Epoch 00038: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6387 - acc: 0.7414 - val_loss: 0.7640 - val_acc: 0.6734\n",
      "Epoch 40/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6377 - acc: 0.7601Epoch 00039: val_acc did not improve\n",
      "\n",
      "Epoch 00039: reducing learning rate to 0.0006400000303983689.\n",
      "1605/1605 [==============================] - 0s - loss: 0.6454 - acc: 0.7558 - val_loss: 0.7755 - val_acc: 0.6684\n",
      "Epoch 41/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6464 - acc: 0.7581Epoch 00040: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6377 - acc: 0.7607 - val_loss: 0.7635 - val_acc: 0.6608\n",
      "Epoch 42/100\n",
      "1520/1605 [===========================>..] - ETA: 0s - loss: 0.6234 - acc: 0.7572Epoch 00041: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6271 - acc: 0.7558 - val_loss: 0.7664 - val_acc: 0.6684\n",
      "Epoch 43/100\n",
      "1440/1605 [=========================>....] - ETA: 0s - loss: 0.6212 - acc: 0.7618Epoch 00042: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6235 - acc: 0.7607 - val_loss: 0.7668 - val_acc: 0.6506\n",
      "Epoch 44/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6262 - acc: 0.7541Epoch 00043: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6321 - acc: 0.7483 - val_loss: 0.7642 - val_acc: 0.6506\n",
      "Epoch 45/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6228 - acc: 0.7601Epoch 00044: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6201 - acc: 0.7639 - val_loss: 0.7657 - val_acc: 0.6684\n",
      "Epoch 46/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6212 - acc: 0.7554Epoch 00045: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6209 - acc: 0.7539 - val_loss: 0.7694 - val_acc: 0.6759\n",
      "Epoch 47/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6244 - acc: 0.7480Epoch 00046: val_acc did not improve\n",
      "\n",
      "Epoch 00046: reducing learning rate to 0.0005120000336319208.\n",
      "1605/1605 [==============================] - 0s - loss: 0.6260 - acc: 0.7483 - val_loss: 0.7678 - val_acc: 0.6532\n",
      "Epoch 48/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6175 - acc: 0.7622Epoch 00047: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6218 - acc: 0.7583 - val_loss: 0.7699 - val_acc: 0.6684\n",
      "Epoch 49/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6155 - acc: 0.7770Epoch 00048: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6125 - acc: 0.7769 - val_loss: 0.7657 - val_acc: 0.6684\n",
      "Epoch 50/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6091 - acc: 0.7764Epoch 00049: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6141 - acc: 0.7738 - val_loss: 0.7709 - val_acc: 0.6633\n",
      "Epoch 51/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.6054 - acc: 0.7750Epoch 00050: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.6051 - acc: 0.7769 - val_loss: 0.7728 - val_acc: 0.6709\n",
      "Epoch 52/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5971 - acc: 0.7838Epoch 00051: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5986 - acc: 0.7807 - val_loss: 0.7697 - val_acc: 0.6582\n",
      "Epoch 53/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5974 - acc: 0.7797Epoch 00052: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5952 - acc: 0.7807 - val_loss: 0.7714 - val_acc: 0.6582\n",
      "Epoch 54/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5998 - acc: 0.7791Epoch 00053: val_acc did not improve\n",
      "\n",
      "Epoch 00053: reducing learning rate to 0.00040960004553198815.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5943 - acc: 0.7807 - val_loss: 0.7685 - val_acc: 0.6582\n",
      "Epoch 55/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5993 - acc: 0.7777Epoch 00054: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5964 - acc: 0.7782 - val_loss: 0.7726 - val_acc: 0.6608\n",
      "Epoch 56/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5906 - acc: 0.7797Epoch 00055: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5945 - acc: 0.7788 - val_loss: 0.7736 - val_acc: 0.6608\n",
      "Epoch 57/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5843 - acc: 0.7777Epoch 00056: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5847 - acc: 0.7769 - val_loss: 0.7730 - val_acc: 0.6582\n",
      "Epoch 58/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5973 - acc: 0.7750Epoch 00057: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5967 - acc: 0.7776 - val_loss: 0.7734 - val_acc: 0.6557\n",
      "Epoch 59/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5853 - acc: 0.7872Epoch 00058: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5853 - acc: 0.7850 - val_loss: 0.7701 - val_acc: 0.6557\n",
      "Epoch 60/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5867 - acc: 0.7831Epoch 00059: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5879 - acc: 0.7819 - val_loss: 0.7731 - val_acc: 0.6557\n",
      "Epoch 61/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5833 - acc: 0.7858Epoch 00060: val_acc did not improve\n",
      "\n",
      "Epoch 00060: reducing learning rate to 0.00032768002711236477.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5832 - acc: 0.7850 - val_loss: 0.7724 - val_acc: 0.6532\n",
      "Epoch 62/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5859 - acc: 0.7885Epoch 00061: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5859 - acc: 0.7882 - val_loss: 0.7724 - val_acc: 0.6608\n",
      "Epoch 63/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5858 - acc: 0.7932Epoch 00062: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5855 - acc: 0.7913 - val_loss: 0.7725 - val_acc: 0.6582\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5774 - acc: 0.7872Epoch 00063: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5786 - acc: 0.7863 - val_loss: 0.7731 - val_acc: 0.6506\n",
      "Epoch 65/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5696 - acc: 0.7872Epoch 00064: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5767 - acc: 0.7838 - val_loss: 0.7758 - val_acc: 0.6658\n",
      "Epoch 66/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5705 - acc: 0.7926Epoch 00065: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5717 - acc: 0.7900 - val_loss: 0.7757 - val_acc: 0.6582\n",
      "Epoch 67/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5844 - acc: 0.7804Epoch 00066: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5799 - acc: 0.7844 - val_loss: 0.7752 - val_acc: 0.6582\n",
      "Epoch 68/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5702 - acc: 0.7993Epoch 00067: val_acc did not improve\n",
      "\n",
      "Epoch 00067: reducing learning rate to 0.0002621440216898918.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5696 - acc: 0.8000 - val_loss: 0.7765 - val_acc: 0.6633\n",
      "Epoch 69/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5610 - acc: 0.7993Epoch 00068: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5620 - acc: 0.7981 - val_loss: 0.7751 - val_acc: 0.6684\n",
      "Epoch 70/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5549 - acc: 0.7973Epoch 00069: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5631 - acc: 0.7938 - val_loss: 0.7792 - val_acc: 0.6557\n",
      "Epoch 71/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5709 - acc: 0.8007Epoch 00070: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5697 - acc: 0.8012 - val_loss: 0.7772 - val_acc: 0.6557\n",
      "Epoch 72/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5725 - acc: 0.7851Epoch 00071: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5714 - acc: 0.7869 - val_loss: 0.7778 - val_acc: 0.6582\n",
      "Epoch 73/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5585 - acc: 0.7905Epoch 00072: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5674 - acc: 0.7882 - val_loss: 0.7773 - val_acc: 0.6557\n",
      "Epoch 74/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5547 - acc: 0.8101Epoch 00073: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5595 - acc: 0.8031 - val_loss: 0.7807 - val_acc: 0.6557\n",
      "Epoch 75/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5598 - acc: 0.8020Epoch 00074: val_acc did not improve\n",
      "\n",
      "Epoch 00074: reducing learning rate to 0.00020971521735191345.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5584 - acc: 0.8000 - val_loss: 0.7803 - val_acc: 0.6532\n",
      "Epoch 76/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5673 - acc: 0.7946Epoch 00075: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5677 - acc: 0.7944 - val_loss: 0.7787 - val_acc: 0.6557\n",
      "Epoch 77/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5684 - acc: 0.7939Epoch 00076: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5643 - acc: 0.7950 - val_loss: 0.7808 - val_acc: 0.6557\n",
      "Epoch 78/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5566 - acc: 0.7953Epoch 00077: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5537 - acc: 0.7975 - val_loss: 0.7820 - val_acc: 0.6532\n",
      "Epoch 79/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5725 - acc: 0.7986Epoch 00078: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5729 - acc: 0.7969 - val_loss: 0.7829 - val_acc: 0.6608\n",
      "Epoch 80/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5383 - acc: 0.8000Epoch 00079: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5418 - acc: 0.7956 - val_loss: 0.7836 - val_acc: 0.6608\n",
      "Epoch 81/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5546 - acc: 0.8034Epoch 00080: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5555 - acc: 0.8012 - val_loss: 0.7840 - val_acc: 0.6532\n",
      "Epoch 82/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5472 - acc: 0.8162Epoch 00081: val_acc did not improve\n",
      "\n",
      "Epoch 00081: reducing learning rate to 0.00016777217388153076.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5500 - acc: 0.8106 - val_loss: 0.7851 - val_acc: 0.6532\n",
      "Epoch 83/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5519 - acc: 0.8007Epoch 00082: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5507 - acc: 0.8031 - val_loss: 0.7828 - val_acc: 0.6608\n",
      "Epoch 84/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5565 - acc: 0.7953Epoch 00083: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5537 - acc: 0.8000 - val_loss: 0.7827 - val_acc: 0.6532\n",
      "Epoch 85/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5537 - acc: 0.8034Epoch 00084: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5527 - acc: 0.8031 - val_loss: 0.7846 - val_acc: 0.6557\n",
      "Epoch 86/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5458 - acc: 0.8081Epoch 00085: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5433 - acc: 0.8081 - val_loss: 0.7852 - val_acc: 0.6557\n",
      "Epoch 87/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5513 - acc: 0.8149Epoch 00086: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5522 - acc: 0.8131 - val_loss: 0.7840 - val_acc: 0.6557\n",
      "Epoch 88/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5532 - acc: 0.8081Epoch 00087: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5565 - acc: 0.8031 - val_loss: 0.7836 - val_acc: 0.6557\n",
      "Epoch 89/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5502 - acc: 0.8041Epoch 00088: val_acc did not improve\n",
      "\n",
      "Epoch 00088: reducing learning rate to 0.00013421773910522462.\n",
      "1605/1605 [==============================] - 0s - loss: 0.5474 - acc: 0.8050 - val_loss: 0.7843 - val_acc: 0.6557\n",
      "Epoch 90/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5503 - acc: 0.8081Epoch 00089: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5510 - acc: 0.8081 - val_loss: 0.7846 - val_acc: 0.6582\n",
      "Epoch 91/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5431 - acc: 0.8000Epoch 00090: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5469 - acc: 0.7994 - val_loss: 0.7853 - val_acc: 0.6532\n",
      "Epoch 92/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5509 - acc: 0.8054Epoch 00091: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5473 - acc: 0.8087 - val_loss: 0.7858 - val_acc: 0.6582\n",
      "Epoch 93/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5465 - acc: 0.8074Epoch 00092: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5532 - acc: 0.8044 - val_loss: 0.7869 - val_acc: 0.6532\n",
      "Epoch 94/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5437 - acc: 0.8142Epoch 00093: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5514 - acc: 0.8093 - val_loss: 0.7843 - val_acc: 0.6532\n",
      "Epoch 95/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5463 - acc: 0.8081Epoch 00094: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5523 - acc: 0.8069 - val_loss: 0.7871 - val_acc: 0.6532\n",
      "Epoch 96/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5595 - acc: 0.7919Epoch 00095: val_acc did not improve\n",
      "\n",
      "Epoch 00095: reducing learning rate to 0.00010737419361248613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605/1605 [==============================] - 0s - loss: 0.5528 - acc: 0.7956 - val_loss: 0.7841 - val_acc: 0.6532\n",
      "Epoch 97/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5504 - acc: 0.8074Epoch 00096: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5501 - acc: 0.8081 - val_loss: 0.7863 - val_acc: 0.6582\n",
      "Epoch 98/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5451 - acc: 0.8203Epoch 00097: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5410 - acc: 0.8212 - val_loss: 0.7865 - val_acc: 0.6557\n",
      "Epoch 99/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5404 - acc: 0.8142Epoch 00098: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5440 - acc: 0.8118 - val_loss: 0.7855 - val_acc: 0.6557\n",
      "Epoch 100/100\n",
      "1480/1605 [==========================>...] - ETA: 0s - loss: 0.5425 - acc: 0.8101Epoch 00099: val_acc did not improve\n",
      "1605/1605 [==============================] - 0s - loss: 0.5399 - acc: 0.8106 - val_loss: 0.7860 - val_acc: 0.6608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8768eeba8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "epochs = 100\n",
    "\n",
    "model.fit(train_features, y_train_oh, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(valid_features, y_validate_oh),\n",
    "          callbacks=[checkpointer, lrreduction])\n",
    "          #callbacks=[checkpointer, earlystopper, lrreduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apaga modelo atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega modelo salvo em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('cifar10.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do treinamento no conjunto de testes com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/500 [==============>...............] - ETA: 0s\n",
      "[INFO] accuracy on the test data set: 68.60% [0.75198]\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_features, y_test_oh, batch_size=10)\n",
    "print(\"\\n[INFO] accuracy on the test data set: {:.2f}% [{:.5f}]\".format(accuracy * 100, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Construindo a nova rede com Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False, weights='imagenet', classes=nb_classes, pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "f1 (Dense)                   (None, 1728)              886464    \n",
      "_________________________________________________________________\n",
      "f2 (Dense)                   (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "f3 (Dense)                   (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 15,822,851\n",
      "Trainable params: 15,822,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "f1 (Dense)                   (None, 1728)              886464    \n",
      "_________________________________________________________________\n",
      "f2 (Dense)                   (None, 128)               221312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "f3 (Dense)                   (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 15,822,851\n",
      "Trainable params: 8,187,587\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#vgg.output.set_shape([None, 1, 1, 512])\n",
    "#x = Flatten(input_shape=vgg.output.shape[1:])(vgg.output)\n",
    "x = Dense(1728, activation='relu', name='f1')(vgg.output)\n",
    "x = Dense(128, activation='relu', name='f2')(x)\n",
    "x = Dropout(0.75)(x)\n",
    "x = Dense(nb_classes, activation='softmax', kernel_regularizer=reg.l2(0.025), name='f3')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "w0, b0, w1, b1, w2, b2, w3, b3, w4, b4 = load_model('my_cifar_dataplus.hdf5').get_weights()\n",
    "\n",
    "# Coloco nas camadas densas finais da rede\n",
    "model.layers[21].set_weights([w3, b3])\n",
    "model.layers[23].set_weights([w4, b4])\n",
    "\n",
    "# camadas que não serão treinadas\n",
    "for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilando a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'\n",
    "#opt = RMSprop()\n",
    "opt = Adam()\n",
    "#opt = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='cifar10.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "lrreduction = ReduceLROnPlateau(monitor='val_acc', patience=7, verbose=1, factor=0.8, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1605 samples, validate on 395 samples\n",
      "Epoch 1/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.2500 - acc: 0.3660Epoch 00000: val_acc improved from -inf to 0.32405, saving model to cifar10.hdf5\n",
      "1605/1605 [==============================] - 7s - loss: 1.2490 - acc: 0.3651 - val_loss: 1.2251 - val_acc: 0.3241\n",
      "Epoch 2/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1641 - acc: 0.3396Epoch 00001: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1639 - acc: 0.3396 - val_loss: 1.1408 - val_acc: 0.3241\n",
      "Epoch 3/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1331 - acc: 0.3541Epoch 00002: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1332 - acc: 0.3514 - val_loss: 1.1286 - val_acc: 0.3241\n",
      "Epoch 4/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1224 - acc: 0.3516- ETA: 0s - loss: 1.1227 - acc: 0.3Epoch 00003: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1224 - acc: 0.3514 - val_loss: 1.1203 - val_acc: 0.3241\n",
      "Epoch 5/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1150 - acc: 0.3528Epoch 00004: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1152 - acc: 0.3514 - val_loss: 1.1148 - val_acc: 0.3241\n",
      "Epoch 6/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1101 - acc: 0.3503Epoch 00005: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1100 - acc: 0.3514 - val_loss: 1.1105 - val_acc: 0.3241\n",
      "Epoch 7/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1064 - acc: 0.3516Epoch 00006: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1064 - acc: 0.3514 - val_loss: 1.1078 - val_acc: 0.3241\n",
      "Epoch 8/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1039 - acc: 0.3528Epoch 00007: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1040 - acc: 0.3514 - val_loss: 1.1058 - val_acc: 0.3241\n",
      "Epoch 9/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1023 - acc: 0.3503Epoch 00008: val_acc did not improve\n",
      "\n",
      "Epoch 00008: reducing learning rate to 0.000800000037997961.\n",
      "1605/1605 [==============================] - 5s - loss: 1.1022 - acc: 0.3514 - val_loss: 1.1043 - val_acc: 0.3241\n",
      "Epoch 10/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1009 - acc: 0.3516Epoch 00009: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1009 - acc: 0.3514 - val_loss: 1.1037 - val_acc: 0.3241\n",
      "Epoch 11/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.1002 - acc: 0.3503Epoch 00010: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.1001 - acc: 0.3514 - val_loss: 1.1029 - val_acc: 0.3241\n",
      "Epoch 12/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0995 - acc: 0.3522Epoch 00011: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0995 - acc: 0.3514 - val_loss: 1.1026 - val_acc: 0.3241\n",
      "Epoch 13/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0990 - acc: 0.3516Epoch 00012: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0991 - acc: 0.3514 - val_loss: 1.1022 - val_acc: 0.3241\n",
      "Epoch 14/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0986 - acc: 0.3528Epoch 00013: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0987 - acc: 0.3514 - val_loss: 1.1019 - val_acc: 0.3241\n",
      "Epoch 15/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0985 - acc: 0.3509Epoch 00014: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0984 - acc: 0.3514 - val_loss: 1.1017 - val_acc: 0.3241\n",
      "Epoch 16/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0984 - acc: 0.3497Epoch 00015: val_acc did not improve\n",
      "\n",
      "Epoch 00015: reducing learning rate to 0.0006400000303983689.\n",
      "1605/1605 [==============================] - 5s - loss: 1.0982 - acc: 0.3514 - val_loss: 1.1015 - val_acc: 0.3241\n",
      "Epoch 17/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.3516Epoch 00016: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0981 - acc: 0.3514 - val_loss: 1.1015 - val_acc: 0.3241\n",
      "Epoch 18/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0982 - acc: 0.3491Epoch 00017: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0980 - acc: 0.3514 - val_loss: 1.1013 - val_acc: 0.3241\n",
      "Epoch 19/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.3516Epoch 00018: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0980 - acc: 0.3514 - val_loss: 1.1014 - val_acc: 0.3241\n",
      "Epoch 20/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0981 - acc: 0.3503Epoch 00019: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0980 - acc: 0.3514 - val_loss: 1.1013 - val_acc: 0.3241\n",
      "Epoch 21/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.3497Epoch 00020: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0979 - acc: 0.3514 - val_loss: 1.1013 - val_acc: 0.3241\n",
      "Epoch 22/50\n",
      "1590/1605 [============================>.] - ETA: 0s - loss: 1.0979 - acc: 0.3516Epoch 00021: val_acc did not improve\n",
      "1605/1605 [==============================] - 5s - loss: 1.0979 - acc: 0.3514 - val_loss: 1.1013 - val_acc: 0.3241\n",
      "Epoch 00021: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe875f07748>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 50\n",
    "\n",
    "model.fit(X_train, y_train_oh, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validate, y_validate_oh),\n",
    "          callbacks=[checkpointer, earlystopper, lrreduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apaga modelo atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega modelo salvo em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('cifar10.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do treinamento no conjunto de testes com o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/500 [========================>.....] - ETA: 0s\n",
      "[INFO] accuracy on the test data set: 34.60% [1.20269]\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test_oh, batch_size=10)\n",
    "print(\"\\n[INFO] accuracy on the test data set: {:.2f}% [{:.5f}]\".format(accuracy * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
